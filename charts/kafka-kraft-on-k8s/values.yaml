global:
  labels: {}
  annotations: {}
  notes:
    enabled: true

# --------------------------------------------------------------------------------------------------------------------------------------- #
# Kafka KRaft
#
# See: https://kafka.apache.org/documentation/#kraft
# --------------------------------------------------------------------------------------------------------------------------------------- #
clusterDomain: cluster.local
kafka:
  enabled: true

  configmap:
    enabled: true # switch to enable kafka properties via configmap
    name: &kafka-properties-cm kafka-properties-cm

    properties:
      service: &kafka-service kafka-svc
      controllerService: &controller-service controller-svc
      namespace: &namespace kafka-test
      brokerReplicas: &kafka_replicas 3
      #
      processRoles: &process-roles broker # "broker" or "broker,controller"
      clusterId: &clusterid QwjfU6MPQ_CMdFsbCx7EGg
      autoCreateTopicsEnable: &auto-create-topics-enable true
      logdirs: &logdirs /mnt/kafka  # "/mnt/kafka" -> no trailing slash
      #
      interBrokerListenerName: &inter-broker-listener-name PLAINTEXT
      advertisedListeners: &advertised-listeners PLAINTEXT://:9092
      listeners: &listeners PLAINTEXT://:9092 # ,CONTROLLER://:9093
      listenersecurityprotocolmap: &listener-security-protocol-map PLAINTEXT:PLAINTEXT,JMX:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
      #
      controllerReplicas: *kafka_replicas
      controllerListenerNames: &controller-listener-names CONTROLLER
      controllerListenerSecurityProtocolMap: &controller-listener-security-protocol-map CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,JMX:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
      #
      defaultReplicationFactor: &default-replication-factor 3
      kafkaNumPartitions: &kafka-num-partitions 8
      offsetsTopicReplicationFactor: &offsets-topic-replication-factor 3
      transactionStateLogReplicationFactor: &transaction-state-log-replication-factor 3
      minInsyncReplicas: &min-insync-replicas 2

  env:
    DEBUG: false # activates debug mode in the pod which executes a sleeping process for a long time.
    ENVS_ENABLED: false # necessary switch to enable kafka properties via envs
    PROCESS_ROLES: *process-roles
    NODE_ID_OFFSET: 1000 # necessary offset for the node id of the brokers, when broker and controller are splitted into seperate clusters by processRoles. see https://kafka.apache.org/documentation/#kraft
    REPLICAS: *kafka_replicas
    SERVICE: *kafka-service
    ADVERTISED_LISTENERS: *advertised-listeners
    LISTENERS: *listeners
    CONTROLLER_SERVICE: *controller-service
    CONTROLLER_REPLICAS: *kafka_replicas
    CONTROLLER_LISTENER_NAMES: *controller-listener-names
    CONTROLLER_LISTENER_SECURITY_PROTOCOL_MAP: *controller-listener-security-protocol-map
    INTER_BROKER_LISTENER_NAME: *inter-broker-listener-name
    NAMESPACE: *namespace
    SHARE_DIR: *logdirs
    # $ kafka-storage.sh random-uuid # 16 bytes
    # see docs: https://kafka.apache.org/33/documentation.html#quickstart_startserver
    CLUSTER_ID: *clusterid
    DEFAULT_REPLICATION_FACTOR: *default-replication-factor
    KAFKA_NUM_PARTITIONS: *kafka-num-partitions
    AUTO_CREATE_TOPICS_ENABLE: *auto-create-topics-enable
    OFFSETS_TOPIC_REPLICATION_FACTOR: *offsets-topic-replication-factor
    TRANSACTION_STATE_LOG_REPLICATION_FACTOR: *transaction-state-log-replication-factor
    MIN_INSYNC_REPLICAS: *min-insync-replicas

  name: kafka
  namespace: *namespace
  labels:
    app: &label kafkakraft
  image:
    repository: kafkakraft/kafkakraft
    pullPolicy: IfNotPresent
    tag: &tag "3.7.0"
  imagePullSecrets: []
  container:
    name: kafka-container

  affinity: {}

  autoscaling:
    enabled: false
    minReplicas: 3
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80

  hpa:
    enabled: false
    minReplicas: 3
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 70
    metrics:
      - type: Resource
        resource:
          name: cpu
          targetAverageUtilization: 50
      - type: Pods
        pods:
          metricName: http_requests
          targetAverageValue: 100

  ingress:
    enabled: false
    className: ""
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  # nameOverride can be set to override the name
  # of the Helm release during a chart deployment
  nameOverride: ""

  # nodeSelector can be set to override the node selection
  nodeSelector: {}

  # ports for the pods and service
  ports:
    # Kafka port for data streaming
    - name: kafka
      port: 9092
    # Controller port
    - name: controller
      port: 9093
    # Prometheus port for JMX metrics
    - name: prometheus
      port: 9000

  # the below `replicaCount` represents
  # the number of replicas in the StatefulSet
  replicaCount: *kafka_replicas

  resources: {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  # mandatory hardening - must be set to disable root user in the container
  # kafka is running as user kafka (1001:1001)
  securityContext:
    runAsNonRoot: true
    fsGroup: 1001
    runAsUser: 1001
    runAsGroup: 1001

  # Service definition with labels and JMX metrics annotations
  #
  # The following is an example of a service definition.
  service:
    name: *kafka-service
    labels:
      app: *kafka-service
    #  Annotations to add to the service
    #  e.g. to enable JMX metrics via Prometheus
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "9000"
    type: ClusterIP
    selector:
      app: *label

  # Specifies whether a service account should be created
  serviceAccount:
    create: false
    name: "kafka-sa"
    # Automatically mount a ServiceAccount's API credentials?
    automount: true
    # Annotations to add to the service account
    annotations: {}
    labels:
      app: *kafka-service

  rbac:
    create: false
    # Whether to create & use RBAC resources or not
    # binding Kafka ServiceAccount to a role
    # that allows Kafka pods querying the K8s API
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: "kafka-rbac"
    apiGroups:
      - "stable.example.com"
    resources:
      - "service"
      - "pods"
    verbs:
      - get
      - list
      - watch
  
  probes:
    livenessProbe:
      enabled: true
      initialDelaySeconds: 15
      periodSeconds: 10
    readinessProbe:
      enabled: true
      initialDelaySeconds: 15
      periodSeconds: 10

  tolerations: []
    # - effect: NoSchedule
    #   key: node-role.kubernetes.io/master
    #   operator: Exists
    # - effect: NoSchedule
    #   key: node-role.kubernetes.io/control-plane
    #   operator: Exists

  # volumeMounts to persist Kafka Data
  volumeMounts:
    - name: &volumename kafka-storage-data
      mountPath: /mnt/kafka
    - name: &kafka-properties-cm-vol kafka-properties-cm-vol
      mountPath: /opt/kafka/config/kraft/properties/

  volumes:
    - name: *kafka-properties-cm-vol
      emptyDir: {}

  # volumeClaimTemplates for the volumeMounts
  volumeClaimTemplates:
    - name: *volumename
      accessModes: ReadWriteOnce
      storage: 100Gi
      # resources:
      #   requests:
      #     storage: 100Gi


# --------------------------------------------------------------------------------------------------------------------------------------- #
# Kafka Controller
#
# see https://kafka.apache.org/documentation/#brokerconfigs_controller.listener.names
# --------------------------------------------------------------------------------------------------------------------------------------- #

controller:
  enabled: true

  configmap:
    enabled: true # switch to enable kafka properties via configmap
    name: &controller-properties-cm controller-properties-cm

    properties:
      service: *kafka-service
      namespace: *namespace
      #
      processRoles: &controller-process-roles 'controller' # "broker" or "broker,controller"
      clusterId: *clusterid
      #
      listeners: &controller-listeners CONTROLLER://:9093
      logdirs: *logdirs # "/mnt/kafka" -> no trailing slash
      #
      controllerReplicas: *kafka_replicas
      controllerService: *controller-service
      controllerListenerNames: *controller-listener-names
      controllerListenerSecurityProtocolMap: *controller-listener-security-protocol-map

  env:
    DEBUG: false # activates debug mode in the pod which executes a sleeping process for a long time.
    ENVS_ENABLED: false # necessary switch to enable controller properties via envs
    PROCESS_ROLES: *controller-process-roles #! Should be always 'controller'. Don't change that until you know what you do.
    CONTROLLER_REPLICAS: *kafka_replicas # matches the replicaCount of Kafka
    SERVICE: *kafka-service
    CONTROLLER_SERVICE: *controller-service
    CONTROLLER_LISTENERS: *controller-listeners
    CONTROLLER_LISTENER_NAMES: *controller-listener-names
    CONTROLLER_LISTENER_SECURITY_PROTOCOL_MAP: *controller-listener-security-protocol-map
    NAMESPACE: *namespace
    SHARE_DIR: *logdirs
    CLUSTER_ID: *clusterid

  name: controller
  namespace: *namespace
  labels:
    app: &controller-label controller
  image:
    repository: kafkakraft/kafka-controller
    pullPolicy: IfNotPresent
    tag: *tag
  imagePullSecrets: []
  container:
    name: controller-container

  # nameOverride can be set to override the name
  # of the Helm release during a chart deployment
  nameOverride: ""

  # nodeSelector can be set to override the node selection
  nodeSelector: {}

  # ports for the pods and service
  ports:
    # Controller port
    - name: controller
      port: 9093
    # Prometheus port for JMX metrics
    - name: prometheus
      port: 9000

  # the below `replicaCount` represents
  # the number of replicas in the StatefulSet
  replicaCount: *kafka_replicas

  resources: {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  # mandatory hardening - must be set to disable root user in the container
  # kafka is running as user kafka (1001:1001)
  securityContext:
    runAsNonRoot: true
    fsGroup: 1001
    runAsUser: 1001
    runAsGroup: 1001

  # Service definition with labels and JMX metrics annotations
  #
  # The following is an example of a service definition.
  service:
    name: *controller-service
    labels:
      app: *controller-service
    #  Annotations to add to the service
    #  e.g. to enable JMX metrics via Prometheus
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "9000"
    type: ClusterIP
    selector:
      app: *controller-label

  # Specifies whether a service account should be created
  serviceAccount:
    create: false
    name: "controller-sa"
    # Automatically mount a ServiceAccount's API credentials?
    automount: true
    # Annotations to add to the service account
    annotations: {}
    labels:
      app: *controller-service

  rbac:
    create: false
    # Whether to create & use RBAC resources or not
    # binding Kafka ServiceAccount to a role
    # that allows Kafka pods querying the K8s API
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: "controller-rbac"
    apiGroups:
      - "stable.example.com"
    resources:
      - "service"
      - "pods"
    verbs:
      - get
      - list
      - watch

  tolerations: []
    # - effect: NoSchedule
    #   key: node-role.kubernetes.io/master
    #   operator: Exists
    # - effect: NoSchedule
    #   key: node-role.kubernetes.io/control-plane
    #   operator: Exists

  volumeMounts:
    - name: &volumename kafka-storage-data
      mountPath: *logdirs
    - name: &controller-properties-cm-vol controller-properties-cm-vol
      mountPath: /opt/kafka/config/kraft/properties/

  volumes:
    - name: *controller-properties-cm-vol
      emptyDir: {}

  # volumeClaimTemplates for the volumeMounts
  volumeClaimTemplates:
    - name: *volumename
      accessModes: ReadWriteOnce
      storage: 100Gi
      # resources:
      #   requests:
      #     storage: 100Gi


# --------------------------------------------------------------------------------------------------------------------------------------- #
# Kafka Connect
#
# see https://kafka.apache.org/documentation/#connect
# --------------------------------------------------------------------------------------------------------------------------------------- #

connect:
  enabled: true

  configmap:
    enabled: true # switch to enable kafka properties via configmap
    name: &connect-properties-cm connect-properties-cm

    properties:
      service: *kafka-service
      service-connect: &service-connect connect-svc
      namespace: *namespace
      #
      keyConverter: &keyconverter org.apache.kafka.connect.json.JsonConverter
      keyConverterSchemasEnable: &keyconverterschemasenable true
      valueConverter: &valueconverter org.apache.kafka.connect.json.JsonConverter
      valueConverterSchemasEnable: &valueconverterschemasenable true
      #
      offsetStorageTopic: connect-offsets
      offsetFlushIntervalMs: 10000
      offsetStorageReplicationFactor: &offsetstoragereplicationfactor 3
      offsetStoragePartitions: &offsetstoragepartitions 25
      offsetStorageCleanupPolicy: &offsetstoragecleanuppolicy compact
      #
      configStorageTopic: connect-configs
      configStorageReplicationFactor: 1
      #
      statusStorageTopic: connect-status
      statusStorageReplicationFactor: &statusstoragereplicationfactor 3
      statusStoragePartitions: &statusstoragepartitions 5
      #
      groupId: kafka-connect-cluster
      listeners: &connect-listeners HTTP://:8083
      pluginPath: &pluginpath /opt/kafka/libs

  env:
    DEBUG: false # activates debug mode in the pod which executes a sleeping process for a long time.
    ENVS_ENABLED: false # necessary switch to enable connect properties via envs
    REPLICAS: &connect_replicas 3
    SERVICE: *kafka-service
    SERVICE_CONNECT: *service-connect
    NAMESPACE: *namespace
    KEY_CONVERTER: *keyconverter
    VALUE_CONVERTER: *valueconverter
    KEY_CONVERTER_SCHEMAS_ENABLE: *keyconverterschemasenable
    VALUE_CONVERTER_SCHEMAS_ENABLE: *valueconverterschemasenable
    OFFSET_STORAGE_REPLICATION_FACTOR: *offsetstoragereplicationfactor
    OFFSET_STORAGE_PARTITIONS: *offsetstoragepartitions
    STATUS_STORAGE_REPLICATION_FACTOR: *statusstoragereplicationfactor
    STATUS_STORAGE_PARTITIONS: *statusstoragepartitions
    OFFSET_STORAGE_CLEANUP_POLICY: *offsetstoragecleanuppolicy
    LISTENERS: *connect-listeners
    PLUGIN_PATH: *pluginpath

  name: connect
  namespace: *namespace
  labels:
    app: &label-connect connect
  image:
    repository: kafkakraft/kafka-connect
    pullPolicy: IfNotPresent
    tag: *tag
  imagePullSecrets: []
  container:
    name: connect-container

  hpa:
    enabled: false
    minReplicas: 3
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 70
    metrics:
      - type: Resource
        resource:
          name: cpu
          targetAverageUtilization: 50
      - type: Pods
        pods:
          metricName: http_requests
          targetAverageValue: 100

  ingress:
    enabled: false
    className: ""
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  # ports for the pods and service
  ports:
    # Kafka port for data streaming
    - name: connect
      port: 8083
    # Prometheus port for JMX metrics
    - name: prometheus
      port: 9000

  # the below `replicaCount` represents
  # the number of replicas in the StatefulSet
  replicaCount: *connect_replicas

  resources: {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  service:
    name: *service-connect
    labels:
      app: *service-connect
    #  Annotations to add to the service
    #  e.g. to enable JMX metrics via Prometheus
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "9000"
    type: ClusterIP
    selector:
      app: *label-connect

  # Specifies whether a service account should be created
  serviceAccount:
    create: false
    name: "connect-sa"
    # Automatically mount a ServiceAccount's API credentials?
    automount: true
    # Annotations to add to the service account
    annotations: {}
    labels:
      app: *service-connect

  rbac:
    create: false
    # Whether to create & use RBAC resources or not
    # binding Kafka ServiceAccount to a role
    # that allows Kafka pods querying the K8s API
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: "connect-rbac"
    apiGroups:
      - "stable.example.com"
    resources:
      - "service"
      - "pods"
    verbs:
      - get
      - list
      - watch

  volumeMounts:
    - name: &connect-properties-cm-vol connect-properties-cm-vol
      mountPath: /opt/kafka/config/connect/

  volumes:
    - name: *connect-properties-cm-vol
      emptyDir: {}
